{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04689d-2cea-40f8-87ea-9199ba4652b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c026bd-550b-4528-9c32-0969ebb0312e",
   "metadata": {},
   "source": [
    "#### create the model architecture from the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bc670-93dc-423d-b7dd-b3bad93fbd11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, no_of_classes):\n",
    "        super(AlexNet,self).__init__()\n",
    "        #construct the cnn layers with sequential\n",
    "        self.convs = nn.Sequential(\n",
    "        #1st conv layer\n",
    "        nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,padding=1),\n",
    "        nn.LocalResponseNorm(size=5),\n",
    "        nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "        nn.ReLU(),\n",
    "        #2nd conv layer\n",
    "        nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5),\n",
    "        nn.LocalResponseNorm(size=5),\n",
    "        nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "        nn.ReLU(),\n",
    "        #3rd conv layer\n",
    "        nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        #4th conv layer\n",
    "        nn.Conv2d(in_channels=384,out_channels=192,kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        #5th conv layer\n",
    "        nn.Conv2d(in_channels=192,out_channels=256,kernel_size=3),\n",
    "        nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        self.classifier=nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        #1st dense layer\n",
    "        nn.Linear(in_features=1024,out_features=4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        #2nd dense layer\n",
    "        nn.Linear(in_features=4096,out_features=4096),\n",
    "        nn.ReLU(),\n",
    "        #3rd dense layer\n",
    "        nn.Linear(in_features=4096,out_features=4096),\n",
    "        nn.Softmax()\n",
    "        )\n",
    "        \n",
    "        def init_parameter():\n",
    "            #We initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01\n",
    "            for layer in self.convs:\n",
    "                nn.init.normal_(layer.weight,mean=0,std=0.1),\n",
    "                nn.init.constant_(layer.bias,0)\n",
    "            nn.init.constant_(self.convs[4].bias,1)\n",
    "            nn.init.constant_(self.convs[10].bias,1)\n",
    "            nn.init.constant_(self.convs[12].bias,1)\n",
    "            nn.init.constant_(self.classifier[2].bias,1)\n",
    "            nn.init.constant_(self.classifier[5].bias,1)\n",
    "            nn.init.constant_(self.classifier[7].bias,1)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            #feed forward\n",
    "            x=self.convs(x)\n",
    "            x=self.classifier(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a5e1f-73f6-4117-bde0-53cba3a6f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "GPUS=[0]\n",
    "EPOCH=90\n",
    "NO_CLASSES=1000\n",
    "TRAIN_DIR=''\n",
    "VAL_DIR=''\n",
    "CHECKPOINT_DIR='/'\n",
    "IMG_DIM=224\n",
    "BATCH_SIZE=128\n",
    "L_RATE=0.01\n",
    "W_DECAY=0.0005\n",
    "MOMENTUM=0.9\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad3009-1488-43eb-9f61-05028f097580",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80417855-ae1d-406f-a354-710430626080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = AlexNet(NO_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad802580-5456-47c2-b5ab-d985d3c43248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with multiple GPU\n",
    "model = torch.nn.parallel.DataParallel(model,device_ids=GPUS)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e382f0-e46b-4a0a-8ca4-f88fbb801d42",
   "metadata": {},
   "source": [
    "### other aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3eaf8-9ccc-4061-aea5-5dcb435831a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image augmentation and transformation\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(IMG_DIM),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5dcc2-68fb-45ff-8f84-07b0275e586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the dataset\n",
    "train_dataset=datasets.ImageFolder(TRAIN_DIR,data_transform)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True,batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb2189-2520-402d-8911-0d02f998ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optim = torch.optim.SGD(model.parameters(),lr=L_RATE,momentum=MOMENTUM,weight_decay=W_DECAY)\n",
    "#loss function\n",
    "loss=nn.CrossEntropyLoss()\n",
    "#decay learning rate\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optim,step_size=50,gamma=0.1)\n",
    "total_step=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e108dd-a2cf-4226-ad59-e91b6a97ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "for epoch in range(EPOCHS):\n",
    "    for step(X,y) in enumerate(train_loader):\n",
    "        X,y=X.to(device),y.to(device)\n",
    "        optim.zero_grad() #refresh gradient\n",
    "        pred=model(X) # forward pass\n",
    "        loss=loss(pred,y).to(device) #take loss\n",
    "        loss.backward() #backward pass\n",
    "        optim.step() #take step\n",
    "        if total_step % 10 == 0:\n",
    "            print(f'step:{total_step} | Loss: {loss}')\n",
    "        total_step +=1\n",
    "        \n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR,f'model_checkpoint{epoch+1}.pkl')\n",
    "    state = {\n",
    "        'epoch':epoch,\n",
    "        'total_step':total_step,\n",
    "        'optimizer':optim.state_dict(),\n",
    "        'model':model.state_dict(),\n",
    "        'seed':seed\n",
    "    }\n",
    "    torch.save(state,checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
